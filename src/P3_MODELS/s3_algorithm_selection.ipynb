{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Selection\n",
    "\n",
    "@roman\n",
    "\n",
    "21 July, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import shap\n",
    "import h3\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from scipy.stats import hmean\n",
    "from INEGIpy import MarcoGeoestadistico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "# show 100 columns in pandas\n",
    "pd.set_option('display.max_columns', 500)\n",
    "TODAY = pd.to_datetime('today')\n",
    "# inegi class\n",
    "inegi_api = MarcoGeoestadistico()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mexico Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read country shape\n",
    "gdf_mexico = inegi_api.Entidades()\n",
    "\n",
    "# change crs to 6372\n",
    "gdf_mexico = gdf_mexico.to_crs(epsg=6372)\n",
    "gdf_mexico.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_properties_data(file_path, cols_to_stay, cols_as_categories):\n",
    "    # Read database\n",
    "    df = pd.read_parquet(file_path)\n",
    "\n",
    "    # Set property_id as index\n",
    "    df = df.set_index('property_id')\n",
    "\n",
    "    # Handling NaNs\n",
    "    df['elevador'] = df['elevador'].fillna(0)\n",
    "    df['cve_vigilancia'] = df['cve_vigilancia'].fillna(0)\n",
    "    df['tipo_vialidad'] = df['tipo_vialidad'].fillna(0)\n",
    "\n",
    "    # Fill missing competitors values with terrain values\n",
    "    df['competitors_weighted_mean_log_price_per_sqm'] = df['competitors_weighted_mean_log_price_per_sqm'].combine_first(df['mean_log_valor_fisico_terreno_m2'])\n",
    "    df['competitors_weighted_mean_log_price_per_sqm_lower'] = df['competitors_weighted_mean_log_price_per_sqm_lower'].combine_first(df['mean_log_valor_fisico_terreno_m2_lower'])\n",
    "    df['competitors_weighted_mean_log_price_per_sqm_upper'] = df['competitors_weighted_mean_log_price_per_sqm_upper'].combine_first(df['mean_log_valor_fisico_terreno_m2_upper'])\n",
    "\n",
    "    # Casting integer columns\n",
    "    columns_to_integer = ['cve_vigilancia', 'tipo_vialidad']\n",
    "    df[columns_to_integer] = df[columns_to_integer].astype('float').round().astype('Int64')\n",
    "\n",
    "    # Feature Engineering\n",
    "    first_date_obs = df['valuation_date'].min()\n",
    "    last_date_obs = df['valuation_date'].max()\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .assign(\n",
    "            year_appraised=lambda x: x['valuation_date'].dt.year,\n",
    "            price_per_sqm=lambda x: x['valor_mercado'] / x['saleable_area'],\n",
    "            quarters_since_first_appraisal=lambda x: (x['valuation_date'] - first_date_obs).dt.days / (30.4 * 3),\n",
    "            conservacion_recat=lambda x: x['conservacion'].replace({7: 3.5}) - x['conservacion'].min(),\n",
    "            cve_vigilancia_recat=lambda x: np.where(x['cve_vigilancia'].eq(2), 1, 0),\n",
    "            superficie_terreno_usable=lambda x: np.where(\n",
    "                x['id_tipo_inmueble'].eq(4),\n",
    "                x['superficie_accesoria'],\n",
    "                x['superficie_terreno'] + x['superficie_accesoria']\n",
    "            ),\n",
    "            elevador=lambda x: x['elevador'].eq(1).astype('int'),\n",
    "            log_superficie_vendible=lambda x: np.log(x['saleable_area']),\n",
    "            log_superficie_terreno=lambda x: np.log(x['superficie_terreno']),\n",
    "            log_superficie_construida=lambda x: np.log(x['superficie_construida']),\n",
    "            log_ing_cor=lambda x: np.log(x['ing_cor']),\n",
    "            recamaras_cat=lambda x: x['recamaras'].clip(0, 5),\n",
    "            banos_cat=lambda x: x['banos'].clip(0, 5),\n",
    "            medios_banos_cat=lambda x: x['medio_banos'].clip(0, 5),\n",
    "            pisos_cat=lambda x: x['niveles'].clip(1, 7),\n",
    "            estacionamiento_cat=lambda x: x['estacionamiento'].clip(0, 1).astype('category'),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Cast columns as categories\n",
    "    df[cols_as_categories] = df[cols_as_categories].astype('category')\n",
    "\n",
    "    # return df.loc[:, cols_to_stay]  not necessary\n",
    "    return df\n",
    "\n",
    "cols_to_categories = [\n",
    "    'property_type', 'cve_vigilancia_recat', 'regimen_propiedad', 'state_id',\n",
    "    'id_tipo_inmueble'\n",
    "]\n",
    "\n",
    "df_properties = get_properties_data(\n",
    "    \"../../data/clean/properties_shif.parquet\", cols_to_stay_with, cols_to_categories\n",
    "    )\n",
    "\n",
    "# see\n",
    "print(df_properties.shape)\n",
    "df_properties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count dtypes\n",
    "df_properties.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see nans\n",
    "df_properties.isna().sum()[df_properties.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data (index)\n",
    "index_train, index_test = train_test_split(\n",
    "    df_properties.index, test_size=0.1, random_state=42, stratify=df_properties['property_type']\n",
    "    )\n",
    "\n",
    "# sizes\n",
    "print(f\"Train size: {len(index_train)}\")\n",
    "print(f\"Test size: {len(index_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of property types\n",
    "df_properties.loc[index_train, 'property_type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of property types\n",
    "df_properties.loc[index_test, 'property_type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y, y_pred, best_percent=1.0):\n",
    "    # Create a DataFrame to hold y, y_pred, and MAPE\n",
    "    df = pd.DataFrame({\n",
    "        'y': y,\n",
    "        'y_pred': y_pred\n",
    "    })\n",
    "    \n",
    "    # Calculate MAPE\n",
    "    df['mape'] = np.abs((df['y'] - df['y_pred']) / df['y'])\n",
    "    \n",
    "    # Determine the threshold MAPE to filter the best_percent data\n",
    "    threshold_mape = df['mape'].quantile(best_percent)\n",
    "    \n",
    "    # Filter the best_percent of the data\n",
    "    df_best = df[df['mape'] <= threshold_mape]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(df_best['y'], df_best['y_pred']))\n",
    "    mae = mean_absolute_error(df_best['y'], df_best['y_pred'])\n",
    "    mape_best = df_best['mape'].mean()\n",
    "    r2 = r2_score(df_best['y'], df_best['y_pred'])\n",
    "    \n",
    "    return pd.Series({\n",
    "        \"rmse\": rmse,\n",
    "        \"mape\": mape_best,\n",
    "        \"mae\": mae,\n",
    "        \"r2\": r2\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost (got stucked in the time consuming of dmatrx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cols to use\n",
    "# cols_x = [\n",
    "#     'id_clase_inmueble', \n",
    "#     # 'property_type',\n",
    "#     'elevador', 'edad_anios',\n",
    "#     # 'regimen_propiedad', 'state_id', 'banos',\n",
    "#     # 'medio_banos', 'estacionamiento', 'saleable_area',\n",
    "#     # 'superficie_terreno_usable', 'distance_to_ocean', 'longitude', 'latitude',\n",
    "#     # 'count_supermarkets_at_1km', 'count_hospitals_at_5km',\n",
    "#     # 'count_metro_at_1km', 'count_schools_at_1km',\n",
    "#     # 'count_restaurants_at_1km',\n",
    "#     # 'competitors_weighted_mean_log_price_per_sqm',\n",
    "#     # 'mean_log_valor_fisico_terreno_m2',\n",
    "#     # 'mean_log_valor_fisico_terreno_m2_lower',\n",
    "#     # 'mean_log_valor_fisico_terreno_m2_upper',\n",
    "#     # 'quarters_since_first_appraisal', 'conservacion_recat',\n",
    "#     # 'cve_vigilancia_recat'\n",
    "# ]\n",
    "\n",
    "# # categorical_cols = [\n",
    "# #     'property_type', 'cve_vigilancia_recat', 'regimen_propiedad', 'state_id'\n",
    "# # ]\n",
    "\n",
    "# # x_train, y_train\n",
    "# X_train = df_properties.loc[index_train, cols_x].copy()\n",
    "# y_train = df_properties['price_per_sqm'].loc[index_train].copy()\n",
    "\n",
    "# # x_test, y_test\n",
    "# X_test = df_properties.loc[index_test, cols_x].copy()\n",
    "# y_test = df_properties['price_per_sqm'].loc[index_test].copy()\n",
    "\n",
    "# # one hot categorical cols\n",
    "# # X_train = pd.get_dummies(X_train, columns=categorical_cols, drop_first=True, dtype='int')\n",
    "# # X_test = pd.get_dummies(X_test, columns=categorical_cols, drop_first=True, dtype='int')\n",
    "\n",
    "# # # distance to ocean: from inf to 100_000\n",
    "# # X_train['distance_to_ocean'] = X_train['distance_to_ocean'].replace(np.inf, 100_000)\n",
    "# # X_test['distance_to_ocean'] = X_test['distance_to_ocean'].replace(np.inf, 100_000)\n",
    "\n",
    "# # set all columns as float\n",
    "# X_train = X_train.astype('float')\n",
    "# X_test = X_test.astype('float')\n",
    "\n",
    "# # see num cols\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate dmatrix\n",
    "# # dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# # dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'objective': 'reg:squarederror',\n",
    "#     'eval_metric': 'rmse',\n",
    "#     'max_depth': 6,\n",
    "#     'eta': 0.01,\n",
    "#     'subsample': 0.8,\n",
    "#     'colsample_bytree': 0.8,\n",
    "#     'enable_categorical': True,\n",
    "#     'seed': 42,\n",
    "#     'nthread': 4,\n",
    "#     'early_stopping_rounds': 50,\n",
    "#     'n_estimators': 1000,\n",
    "#     'verbose': 1\n",
    "# }\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "# xgb_model = xgb.XGBRegressor(**params)\n",
    "# xgb_model.fit(\n",
    "#     X_train, y_train,\n",
    "#     eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self):\n",
    "        self.harmonic_means_ = {}\n",
    "        self.default_mean_ = None\n",
    "        self.first_category_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Ensure X is a DataFrame and has exactly 2 columns\n",
    "        if not isinstance(X, pd.DataFrame) or X.shape[1] != 2:\n",
    "            raise ValueError(\"X must be a DataFrame with exactly 2 columns.\")\n",
    "        \n",
    "        # Ensure y is a Series or ndarray with the same length as X\n",
    "        if len(y) != len(X):\n",
    "            raise ValueError(\"Length of y must be equal to the number of rows in X.\")\n",
    "        \n",
    "        # Create a DataFrame with y included\n",
    "        df = X.copy()\n",
    "        df['y'] = y\n",
    "        \n",
    "        # Calculate harmonic means for each combination of categories\n",
    "        grouped = df.groupby(list(X.columns))['y']\n",
    "        self.harmonic_means_ = grouped.apply(lambda grp: hmean(grp)).to_dict()\n",
    "        \n",
    "        # Calculate the default mean as the harmonic mean of the first category\n",
    "        self.first_category_ = X.columns[0]\n",
    "        first_category = df.iloc[0][self.first_category_]\n",
    "        \n",
    "        if first_category:\n",
    "            first_category_df = df[df[self.first_category_] == first_category]\n",
    "            if not first_category_df.empty:\n",
    "                # Calculate harmonic mean for each level of the second category\n",
    "                category_means = first_category_df.groupby(X.columns[1])['y'].apply(lambda grp: hmean(grp))\n",
    "                # Calculate the overall harmonic mean of these category means\n",
    "                if not category_means.empty:\n",
    "                    self.default_mean_ = hmean(category_means.values)\n",
    "                else:\n",
    "                    self.default_mean_ = np.nan\n",
    "            else:\n",
    "                self.default_mean_ = np.nan\n",
    "        else:\n",
    "            self.default_mean_ = np.nan\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Ensure X is a DataFrame and has exactly 2 columns\n",
    "        if not isinstance(X, pd.DataFrame) or X.shape[1] != 2:\n",
    "            raise ValueError(\"X must be a DataFrame with exactly 2 columns.\")\n",
    "        \n",
    "        # Create a DataFrame for predictions\n",
    "        X_copy = X.copy()\n",
    "        X_copy['prediction'] = X_copy.apply(lambda row: self.harmonic_means_.get(tuple(row), self.default_mean_), axis=1)\n",
    "        return X_copy['prediction'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols to use\n",
    "cols_x = [\n",
    "    'state_id', 'year_appraised'\n",
    "]\n",
    "\n",
    "# x_train, y_train\n",
    "X_train = df_properties.drop(columns=['price_per_sqm']).loc[index_train, cols_x].copy()\n",
    "y_train = df_properties['price_per_sqm'].loc[index_train].copy()\n",
    "\n",
    "# x_test, y_test\n",
    "X_test = df_properties.drop(columns=['price_per_sqm']).loc[index_test, cols_x].copy()\n",
    "y_test = df_properties['price_per_sqm'].loc[index_test].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit baseline model\n",
    "baseline_model = BaselineModel()\n",
    "baseline_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train \n",
    "y_train_pred = baseline_model.predict(X_train)\n",
    "calculate_metrics(y_train, y_train_pred, best_percent=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "y_test_pred = baseline_model.predict(X_test)\n",
    "calculate_metrics(y_test, y_test_pred, best_percent=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHF Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties.filter(like='super')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols to use\n",
    "cols_x = [\n",
    "    'id_tipo_inmueble',\n",
    "    'log_superficie_vendible',\n",
    "    'log_superficie_construida',\n",
    "    'log_ing_cor',\n",
    "    'banos_cat',\n",
    "    'medios_banos_cat',\n",
    "    'pisos_cat',\n",
    "    'recamaras_cat',\n",
    "    'estacionamiento_cat'\n",
    "]\n",
    "\n",
    "# x_train, y_train\n",
    "X_train = df_properties.loc[index_train, cols_x].copy()\n",
    "y_train = np.log(df_properties['price_per_sqm'].loc[index_train]).copy()\n",
    "\n",
    "# x_test, y_test\n",
    "X_test = df_properties.loc[index_test, cols_x].copy()\n",
    "y_test = np.log(df_properties['price_per_sqm'].loc[index_test]).copy()\n",
    "\n",
    "# one hot encode id_tipo_inmueble\n",
    "X_train = pd.get_dummies(X_train, columns=['id_tipo_inmueble'], drop_first=True, dtype='int')\n",
    "X_test = pd.get_dummies(X_test, columns=['id_tipo_inmueble'], drop_first=True, dtype='int')\n",
    "\n",
    "# set all columns as float\n",
    "X_train = X_train.astype('float')\n",
    "X_test = X_test.astype('float')\n",
    "\n",
    "# see num cols\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see cols\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit linear regression\n",
    "shf_linear_model = LinearRegression()\n",
    "shf_linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add X_train the price_per_sqm col\n",
    "X_train_bis = X_train.copy()\n",
    "X_train_bis['price_per_sqm'] = np.exp(y_train)\n",
    "\n",
    "cols_to_use = X_train_bis.columns.tolist()\n",
    "cols_to_use.remove('price_per_sqm')\n",
    "\n",
    "# fit linear regression using smf\n",
    "shf_linear_model_smf = smf.ols(\n",
    "    formula='np.log(price_per_sqm) ~ ' + ' + '.join(cols_to_use),\n",
    "    data=X_train_bis\n",
    "    )\n",
    "shf_linear_model_smf = shf_linear_model_smf.fit()\n",
    "\n",
    "# summary\n",
    "shf_linear_model_smf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties['id_tipo_inmueble'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "y_train_pred = shf_linear_model.predict(X_train)\n",
    "calculate_metrics(np.exp(y_train), np.exp(y_train_pred), best_percent=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "y_test_pred = shf_linear_model.predict(X_test)\n",
    "calculate_metrics(np.exp(y_test), np.exp(y_test_pred), best_percent=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols to use\n",
    "cols_x = [\n",
    "    'mean_log_valor_fisico_terreno_m2', 'quarters_since_first_appraisal', 'conservacion_recat', 'id_clase_inmueble',\n",
    "    'competitors_weighted_mean_log_price_per_sqm', 'saleable_area', 'elevador', 'banos',\n",
    "    'medio_banos', 'estacionamiento', 'superficie_terreno_usable', 'property_type', 'state_id'\n",
    "]\n",
    "\n",
    "# x_train, y_train\n",
    "X_train = df_properties.loc[index_train, cols_x].copy()\n",
    "y_train = np.log(df_properties['price_per_sqm'].loc[index_train].copy())\n",
    "\n",
    "# x_test, y_test\n",
    "X_test = df_properties.loc[index_test, cols_x].copy()\n",
    "y_test = np.log(df_properties['price_per_sqm'].loc[index_test].copy())\n",
    "\n",
    "# one hot encode property_type, state_id\n",
    "X_train = pd.get_dummies(X_train, columns=['property_type', 'state_id'], drop_first=True, dtype='int')\n",
    "X_test = pd.get_dummies(X_test, columns=['property_type', 'state_id'], drop_first=True, dtype='int')\n",
    "\n",
    "# see num cols\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see cols\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit linear regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "y_train_pred = linear_model.predict(X_train)\n",
    "calculate_metrics(np.exp(y_train), np.exp(y_train_pred), best_percent=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "y_test_pred = linear_model.predict(X_test)\n",
    "calculate_metrics(np.exp(y_test), np.exp(y_test_pred), best_percent=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols to use\n",
    "cols_x = [\n",
    "    'mean_log_valor_fisico_terreno_m2', 'quarters_since_first_appraisal', 'conservacion_recat', 'id_clase_inmueble',\n",
    "    'competitors_weighted_mean_log_price_per_sqm', 'saleable_area', 'elevador', 'banos',\n",
    "    'medio_banos', 'estacionamiento', 'superficie_terreno_usable', 'property_type', 'state_id'\n",
    "]\n",
    "\n",
    "# x_train, y_train\n",
    "X_train = df_properties.loc[index_train, cols_x].copy()\n",
    "y_train = df_properties['price_per_sqm'].loc[index_train].copy()\n",
    "\n",
    "# x_test, y_test\n",
    "X_test = df_properties.loc[index_test, cols_x].copy()\n",
    "y_test = df_properties['price_per_sqm'].loc[index_test].copy()\n",
    "\n",
    "# one hot encode property_type, state_id\n",
    "X_train = pd.get_dummies(X_train, columns=['property_type', 'state_id'], drop_first=True, dtype='int')\n",
    "X_test = pd.get_dummies(X_test, columns=['property_type', 'state_id'], drop_first=True, dtype='int')\n",
    "\n",
    "# see num cols\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit decision tree\n",
    "tree_model = DecisionTreeRegressor(\n",
    "    random_state=42,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5\n",
    "    )\n",
    "tree_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "y_train_pred = tree_model.predict(X_train)\n",
    "calculate_metrics(y_train, y_train_pred, best_percent=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "y_test_pred = tree_model.predict(X_test)\n",
    "calculate_metrics(y_test, y_test_pred, best_percent=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols to use\n",
    "cols_x = [\n",
    "    'id_clase_inmueble', \n",
    "    'property_type',\n",
    "    'elevador', 'edad_anios',\n",
    "    'regimen_propiedad', 'state_id', 'banos',\n",
    "    'medio_banos', 'estacionamiento', 'saleable_area',\n",
    "    'superficie_terreno_usable', 'distance_to_ocean', 'longitude', 'latitude',\n",
    "    'count_supermarkets_at_1km', 'count_hospitals_at_5km',\n",
    "    'count_metro_at_1km', 'count_schools_at_1km',\n",
    "    'count_restaurants_at_1km',\n",
    "    'competitors_weighted_mean_log_price_per_sqm',\n",
    "    'mean_log_valor_fisico_terreno_m2',\n",
    "    'mean_log_valor_fisico_terreno_m2_lower',\n",
    "    'mean_log_valor_fisico_terreno_m2_upper',\n",
    "    'quarters_since_first_appraisal', 'conservacion_recat',\n",
    "    'cve_vigilancia_recat'\n",
    "]\n",
    "\n",
    "categorical_cols = [\n",
    "    'property_type', 'cve_vigilancia_recat', 'regimen_propiedad', 'state_id'\n",
    "]\n",
    "\n",
    "# x_train, y_train\n",
    "X_train = df_properties.loc[index_train, cols_x].copy()\n",
    "y_train = df_properties['price_per_sqm'].loc[index_train].copy()\n",
    "\n",
    "# x_test, y_test\n",
    "X_test = df_properties.loc[index_test, cols_x].copy()\n",
    "y_test = df_properties['price_per_sqm'].loc[index_test].copy()\n",
    "\n",
    "# # distance to ocean: from inf to 100_000\n",
    "X_train['distance_to_ocean'] = X_train['distance_to_ocean'].replace(np.inf, 100_000)\n",
    "X_test['distance_to_ocean'] = X_test['distance_to_ocean'].replace(np.inf, 100_000)\n",
    "\n",
    "\n",
    "# see num cols\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see distance to ocean categories\n",
    "X_train['distance_to_ocean'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset train data to get validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit catboost\n",
    "params = {\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.05,\n",
    "    'l2_leaf_reg': 3,\n",
    "    'loss_function': 'MAE',\n",
    "    'eval_metric': 'MAPE',\n",
    "    'iterations': 1000,\n",
    "    'early_stopping_rounds': 50,\n",
    "    'random_seed': 42,\n",
    "    'verbose': 100,\n",
    "    'use_best_model': True\n",
    "}\n",
    "\n",
    "# create pool\n",
    "pool_train = Pool(X_train, y_train, cat_features=categorical_cols)\n",
    "pool_val = Pool(X_val, y_val, cat_features=categorical_cols)\n",
    "pool_test = Pool(X_test, y_test, cat_features=categorical_cols)\n",
    "\n",
    "# train\n",
    "catboost_model = CatBoostRegressor(**params)\n",
    "catboost_model.fit(\n",
    "    pool_train,\n",
    "    eval_set=pool_val,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "y_train_pred = catboost_model.predict(pool_train)\n",
    "calculate_metrics(y_train, y_train_pred, best_percent=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "y_test_pred = catboost_model.predict(pool_test)\n",
    "calculate_metrics(y_test, y_test_pred, best_percent=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols to use\n",
    "cols_x = [\n",
    "    'id_clase_inmueble', \n",
    "    'property_type',\n",
    "    'elevador', 'edad_anios',\n",
    "    'regimen_propiedad', 'state_id', 'banos',\n",
    "    'medio_banos', 'estacionamiento', 'saleable_area',\n",
    "    'superficie_terreno_usable', 'distance_to_ocean', 'longitude', 'latitude',\n",
    "    'count_supermarkets_at_1km', 'count_hospitals_at_5km',\n",
    "    'count_metro_at_1km', 'count_schools_at_1km',\n",
    "    'count_restaurants_at_1km',\n",
    "    'competitors_weighted_mean_log_price_per_sqm',\n",
    "    'mean_log_valor_fisico_terreno_m2',\n",
    "    'mean_log_valor_fisico_terreno_m2_lower',\n",
    "    'mean_log_valor_fisico_terreno_m2_upper',\n",
    "    'quarters_since_first_appraisal', 'conservacion_recat',\n",
    "    'cve_vigilancia_recat'\n",
    "]\n",
    "\n",
    "categorical_cols = [\n",
    "    'property_type', 'cve_vigilancia_recat', 'regimen_propiedad', 'state_id'\n",
    "]\n",
    "\n",
    "# x_train, y_train\n",
    "X_train = df_properties.loc[index_train, cols_x].copy()\n",
    "y_train = df_properties['price_per_sqm'].loc[index_train].copy()\n",
    "\n",
    "# x_test, y_test\n",
    "X_test = df_properties.loc[index_test, cols_x].copy()\n",
    "y_test = df_properties['price_per_sqm'].loc[index_test].copy()\n",
    "\n",
    "# # distance to ocean: from inf to 100_000\n",
    "X_train['distance_to_ocean'] = X_train['distance_to_ocean'].replace(np.inf, 100_000)\n",
    "X_test['distance_to_ocean'] = X_test['distance_to_ocean'].replace(np.inf, 100_000)\n",
    "\n",
    "\n",
    "# see num cols\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set best model\n",
    "best_model = catboost_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict all data in  test\n",
    "y_pred = best_model.predict(pool_test)\n",
    "\n",
    "# save in X_test\n",
    "X_test['y_pred'] = y_pred\n",
    "X_test['y_true'] = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors\n",
    "X_test['error'] = X_test['y_true'] - X_test['y_pred']\n",
    "X_test['error_perc'] = X_test['error'] / X_test['y_true']\n",
    "X_test['error_perc_abs'] = X_test['error_perc'].abs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate metrics\n",
    "metrics_all = calculate_metrics(y_test, y_pred, best_percent=1)\n",
    "metrics_best_90 = calculate_metrics(y_test, y_pred, best_percent=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print metrics\n",
    "pd.DataFrame([metrics_all, metrics_best_90], index=['All', 'Best 90%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of errors\n",
    "sns.histplot(\n",
    "    X_test,\n",
    "    x='error_perc',\n",
    "    bins=100,\n",
    "    kde=True\n",
    ")\n",
    "# addorn\n",
    "plt.title(\"Error Percentage Histogram\")\n",
    "plt.xlabel(\"Error Percentage\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best 90% histogram\n",
    "sns.histplot(\n",
    "    X_test[X_test['error_perc_abs'] <= X_test['error_perc_abs'].quantile(0.9)],\n",
    "    x='error_perc',\n",
    "    bins=100,\n",
    "    kde=True\n",
    ")\n",
    "# addorn\n",
    "plt.title(\"Error Percentage Histogram (Best 90%)\")\n",
    "plt.xlabel(\"Error Percentage\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors for propertytype\n",
    "(\n",
    "    X_test\n",
    "    .groupby('property_type', observed=True)\n",
    "    .apply(lambda x: calculate_metrics(x['y_true'], x['y_pred'], best_percent=0.9), include_groups=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors for propertytype\n",
    "(\n",
    "    X_test\n",
    "    .groupby('cve_vigilancia_recat', observed=True)\n",
    "    .apply(lambda x: calculate_metrics(x['y_true'], x['y_pred'], best_percent=0.9), include_groups=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors for propertytype\n",
    "(\n",
    "    X_test\n",
    "    .groupby('regimen_propiedad', observed=True)\n",
    "    .apply(lambda x: calculate_metrics(x['y_true'], x['y_pred'], best_percent=0.9), include_groups=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors for state_id (only get mape)\n",
    "table_errors_state = (\n",
    "    X_test\n",
    "    .groupby('state_id', observed=True)\n",
    "    .apply(lambda x: calculate_metrics(x['y_true'], x['y_pred'], best_percent=0.9), include_groups=False)\n",
    ")\n",
    "table_errors_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see error upfront_beach of beach vs not infront of beach\n",
    "(\n",
    "    X_test\n",
    "    .groupby('distance_to_ocean', observed=True)\n",
    "    .apply(lambda x: calculate_metrics(x['y_true'], x['y_pred'], best_percent=0.9), include_groups=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize errors over time\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "sns.regplot(\n",
    "    x='quarters_since_first_appraisal',\n",
    "    y='error_perc',\n",
    "    data=X_test,\n",
    "    scatter_kws={'alpha': 0.1},\n",
    "    line_kws={'color': 'red'},\n",
    "    ax=ax,\n",
    "    lowess=True\n",
    ")\n",
    "\n",
    "# addorn\n",
    "plt.title(\"Error Percentage Over Time\")\n",
    "plt.xlabel(\"Quarters Since First Appraisal\")\n",
    "plt.ylabel(\"Error Percentage\")\n",
    "\n",
    "# add legend\n",
    "plt.legend(['Data', 'Lowess'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust linear regression to error_perc\n",
    "lm_time_error = smf.ols('error_perc ~ quarters_since_first_appraisal', data=X_test).fit()\n",
    "\n",
    "# see summary\n",
    "lm_time_error.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geospatial Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot MAPE by state\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "(\n",
    "    gdf_mexico\n",
    "    .merge(\n",
    "        table_errors_state.reset_index(),\n",
    "        left_on='cvegeo',\n",
    "        right_on='state_id',\n",
    "        how='left'\n",
    "    )\n",
    "    .plot('mape', legend=True, ax=ax, cmap='copper', edgecolor='gray')\n",
    ")\n",
    "\n",
    "# dont show axis\n",
    "plt.axis('off')\n",
    "\n",
    "# title\n",
    "plt.title('MAPE by state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_errors(df, col):\n",
    "    # visualize errors over time\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    sns.regplot(\n",
    "        x=col,\n",
    "        y='error_perc',\n",
    "        data=df,\n",
    "        scatter_kws={'alpha': 0.1},\n",
    "        line_kws={'color': 'red'},\n",
    "        ax=ax,\n",
    "        lowess=True\n",
    "    )\n",
    "\n",
    "    # addorn\n",
    "    plt.title(f\"Error Percentage by {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Error Percentage\")\n",
    "\n",
    "    # add legend\n",
    "    plt.legend(['Data', 'Lowess'])\n",
    "\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize errors by categories\n",
    "cols_x = [\n",
    "    'elevador',\n",
    "    'edad_anios',\n",
    "    'banos',\n",
    "    'medio_banos',\n",
    "    'estacionamiento',\n",
    "    'saleable_area',\n",
    "    'superficie_terreno_usable',\n",
    "    'distance_to_ocean',\n",
    "    'count_supermarkets_at_1km',\n",
    "    'count_hospitals_at_5km',\n",
    "    'count_metro_at_1km',\n",
    "    'count_schools_at_1km',\n",
    "    'count_restaurants_at_1km',\n",
    "    # 'competitors_weighted_mean_log_price_per_sqm',\n",
    "    # 'mean_log_valor_fisico_terreno_m2',\n",
    "    # 'mean_log_valor_fisico_terreno_m2_lower',\n",
    "    # 'mean_log_valor_fisico_terreno_m2_upper',\n",
    "    # 'quarters_since_first_appraisal', \n",
    "    # 'cve_vigilancia_recat'\n",
    "]\n",
    "\n",
    "for col in cols_x:\n",
    "    visualize_errors(X_test, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series in special zones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zones of interest:\n",
    "- Andares, Guadalajara 8849ab4b45fffff\n",
    "- Ruben Darío, Mexico City 884995bae9fffff\n",
    "- Roma Norte, Mexico City 884995ba3dfffff\n",
    "- Centrito Valle, Monterrey 8848a20667fffff\n",
    "- Puerto Cancún, Cancún 884519b491fffff\n",
    "\n",
    "The counterfactual will be the same property in different zones during the same period.\n",
    "\n",
    "\n",
    "The property will be:\n",
    "- id_clase_inmueble: 4 (media residencial)\n",
    "- property_type: apartment\n",
    "- elevador: 1\n",
    "- edad_anios: 0 (new)\n",
    "- regimen_propiedad: PRIVADA COLECTIVA\n",
    "- state_id: (depends on the hex)\n",
    "- banos: 2\n",
    "- medio_banos: 1\n",
    "- estacionamiento: 2\n",
    "- saleable_area: 100\n",
    "- superficie_terreno_usable: 100\n",
    "- distance_to_ocean: 100000\n",
    "- longitude: (depends on the hex)\n",
    "- latitude: (depends on the hex)\n",
    "- count_supermarkets_at_1km: 1\n",
    "- count_hospitals_at_5km: 1\n",
    "- count_metro_at_1km: 1\n",
    "- count_schools_at_1km: 1\n",
    "- count_restaurants_at_1km: 1\n",
    "- competitors_weighted_mean_log_price_per_sqm: (depends on the hex)\n",
    "- mean_log_valor_fisico_terreno_m2: (depends on the hex)\n",
    "- mean_log_valor_fisico_terreno_m2_lower: (depends on the hex)\n",
    "- mean_log_valor_fisico_terreno_m2_upper: (depends on the hex)\n",
    "- quarters_since_first_appraisal: (time series)\n",
    "- conservacion_recat: 3\n",
    "- cve_vigilancia_recat: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_counterfactual_property(h_id, df):\n",
    "    \"\"\"\n",
    "    Generate a counterfactual property based on a given hex id.\n",
    "    The property should have:\n",
    "\n",
    "    - id_clase_inmueble: 4\n",
    "    - property_type: 'apartment'\n",
    "    - elevador: 1\n",
    "    - edad_anios: 0\n",
    "    - regimen_propiedad: 'PRIVADA COLECTIVA'\n",
    "    - state_id: based on the hex_id\n",
    "    - banos: 2\n",
    "    - medio_banos: 1\n",
    "    - estacionamiento: 1\n",
    "    - saleable_area: 100\n",
    "    - superficie_terreno_usable: 100\n",
    "    - distance_to_ocean: 100_000\n",
    "    - longitude: based on the hex_id\n",
    "    - latitude: based on the hex_id\n",
    "    - count_supermarkets_at_1km: 1\n",
    "    - count_hospitals_at_5km: 1\n",
    "    - count_metro_at_1km: 0\n",
    "    - count_schools_at_1km: 1\n",
    "    - count_restaurants_at_1km: 1\n",
    "    - competitors_weighted_mean_log_price_per_sqm: based on the hex_id and quarter (doing a regression)\n",
    "    - mean_log_valor_fisico_terreno_m2: based on the hex_id\n",
    "    - mean_log_valor_fisico_terreno_m2_lower: based on the hex_id\n",
    "    - mean_log_valor_fisico_terreno_m2_upper: based on the hex_id\n",
    "    - quarters_since_first_appraisal: (time range from 0 to 20)\n",
    "    - conservacion_recat: 3\n",
    "    - cve_vigilancia_recat: 1\n",
    "    \"\"\"\n",
    "    # Step 0: generate Series with fixed values\n",
    "    s = pd.Series({\n",
    "        'id_clase_inmueble': 6,\n",
    "        'property_type': 'apartment',\n",
    "        'elevador': 1,\n",
    "        'edad_anios': 0,\n",
    "        'regimen_propiedad': 'PRIVADA COLECTIVA',\n",
    "        'banos': 1,\n",
    "        'medio_banos': 1,\n",
    "        'estacionamiento': 1,\n",
    "        'saleable_area': 60,\n",
    "        'superficie_terreno_usable': 60,\n",
    "        'distance_to_ocean': 100_000,\n",
    "        'count_supermarkets_at_1km': 1,\n",
    "        'count_hospitals_at_5km': 1,\n",
    "        'count_metro_at_1km': 0,\n",
    "        'count_schools_at_1km': 1,\n",
    "        'count_restaurants_at_1km': 1,\n",
    "        'conservacion_recat': 3,\n",
    "        'cve_vigilancia_recat': 1\n",
    "    })\n",
    "\n",
    "    # Step 1: get hex_id info\n",
    "    # get hex_id info\n",
    "    df = (\n",
    "        df.copy()\n",
    "        .query('hex_id == @h_id')\n",
    "    )\n",
    "    # get lat and long using h3_to_geo\n",
    "    s['longitude'], s['latitude'] = h3.h3_to_geo(h_id)\n",
    "    # get state_id\n",
    "    s['state_id'] = df['state_id'].values[0]\n",
    "    # get mean_log_valor_fisico_terreno_m2\n",
    "    s['mean_log_valor_fisico_terreno_m2'] = df['mean_log_valor_fisico_terreno_m2'].apply(hmean).values[0]\n",
    "    s['mean_log_valor_fisico_terreno_m2_lower'] = df['mean_log_valor_fisico_terreno_m2_lower'].apply(hmean).values[0]\n",
    "    s['mean_log_valor_fisico_terreno_m2_upper'] = df['mean_log_valor_fisico_terreno_m2_upper'].apply(hmean).values[0]\n",
    "\n",
    "    # Step 2: generate 20 counterfactuals but changing the quarters_since_first_appraisal from 0 to 20\n",
    "    counterfactuals = []\n",
    "    for i in range(21):\n",
    "        s['quarters_since_first_appraisal'] = i\n",
    "        counterfactuals.append(s.copy())\n",
    "    \n",
    "    # generate df\n",
    "    df_counterfactuals = pd.DataFrame(counterfactuals)\n",
    "\n",
    "    # Step 3: get competitors_weighted_mean_log_price_per_sqm\n",
    "    # adjust a linear regression model\n",
    "    x_variables = [\n",
    "        # 'banos',\n",
    "        # 'estacionamiento',\n",
    "        'saleable_area',\n",
    "        'quarters_since_first_appraisal'\n",
    "    ]\n",
    "    # x & y\n",
    "    X = df.copy()[x_variables]\n",
    "    y = np.log(df['price_per_sqm'])\n",
    "\n",
    "    # fit\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X, y)\n",
    "    # predict in counterfactuals\n",
    "    x_counterfactuals = df_counterfactuals[x_variables].copy()\n",
    "    # look beta of quarters_since_first_appraisal, if it is negative, then only predict for the quarter 10\n",
    "    if lm.coef_[-1] < 0:\n",
    "        x_counterfactuals['quarters_since_first_appraisal'] = 10\n",
    "        df_counterfactuals['competitors_weighted_mean_log_price_per_sqm'] = lm.predict(x_counterfactuals[X.columns])\n",
    "    else:\n",
    "        df_counterfactuals['competitors_weighted_mean_log_price_per_sqm'] = lm.predict(x_counterfactuals)\n",
    "    \n",
    "    # see betas\n",
    "    print(dict(zip(x_variables, lm.coef_)))\n",
    "\n",
    "    return df_counterfactuals\n",
    "\n",
    "# generate counterfactuals for 5 hex_ids\n",
    "hex_ids_counterfactuals = [\n",
    "    '8849ab4b45fffff',\n",
    "    # '884995bae9fffff',\n",
    "    '884995ba27fffff',\n",
    "    '884995ba3dfffff',\n",
    "    '8848a20667fffff',\n",
    "    '884519b491fffff'\n",
    "]\n",
    "\n",
    "# counterfactuals, append the hex_id as index\n",
    "X_counterfactuals = pd.concat(\n",
    "    [generate_counterfactual_property(h_id, df_properties) for h_id in hex_ids_counterfactuals],\n",
    "    keys=hex_ids_counterfactuals\n",
    ")\n",
    "\n",
    "# predict price per sqm\n",
    "X_counterfactuals['price_per_sqm_pred'] = best_model.predict(Pool(X_counterfactuals, cat_features=categorical_cols))\n",
    "\n",
    "# plot price per sqm pred vs quarters_since_first_appraisal for each hex_id\n",
    "X_counterfactuals = X_counterfactuals.reset_index().rename(columns={'level_0': 'hex_id'})\n",
    "\n",
    "# map hex_id to name\n",
    "dict_hex_id_to_name = {\n",
    "    '8849ab4b45fffff': 'andares-gdl',\n",
    "    # '884995bae9fffff': 'ruben-dario-cdmx',\n",
    "    '884995ba3dfffff': 'roma-norte-cdmx',\n",
    "    '884995ba27fffff': 'doctores-cdmx',\n",
    "    '8848a20667fffff': 'centrito-valle-mty',\n",
    "    '884519b491fffff': 'pto-cancun-cancun'\n",
    "}\n",
    "X_counterfactuals['zone'] = X_counterfactuals['hex_id'].map(dict_hex_id_to_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import QuarterEnd\n",
    "\n",
    "# get first day of the minimum date\n",
    "first_date_obs = df_properties['valuation_date'].min().to_period('Q').to_timestamp()\n",
    "\n",
    "# create a column of the date of the appraisal using first_date_obs + quarters_since_first_appraisal\n",
    "X_counterfactuals['date'] = X_counterfactuals['quarters_since_first_appraisal'].apply(\n",
    "    lambda x: first_date_obs + QuarterEnd(x)\n",
    ")\n",
    "\n",
    "# see\n",
    "X_counterfactuals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.lineplot(\n",
    "    x='date',\n",
    "    y='price_per_sqm_pred',\n",
    "    hue='zone',\n",
    "    data=X_counterfactuals,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# y ticks as money\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "def money_fmt(x, pos):\n",
    "    return f\"${x:,.0f}\"\n",
    "\n",
    "formatter = FuncFormatter(money_fmt)\n",
    "ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "# every quarter add a tick\n",
    "# import matplotlib.dates as mdates\n",
    "# ax.xaxis.set_major_locator(mdates.MonthLocator(interval=12))\n",
    "# ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "\n",
    "\n",
    "\n",
    "# addorn\n",
    "plt.title(\"Price Per sqm Prediction Over Time\")\n",
    "plt.xlabel(\"Quarters Since First Appraisal\")\n",
    "plt.ylabel(\"Price per sqm\")\n",
    "plt.legend(title='Zone')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a cuadratic model to the data\n",
    "lm_appraisal_time = smf.ols(\n",
    "    formula=\"price_per_sqm_pred ~ quarters_since_first_appraisal*zone\",\n",
    "    data=X_counterfactuals\n",
    ").fit()\n",
    "\n",
    "# see summary\n",
    "lm_appraisal_time.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest plot for the slopes\n",
    "df_slopes = pd.DataFrame({\n",
    "    'zone': lm_appraisal_time.params.index[lm_appraisal_time.params.index.str.contains('quarters_since_first_appraisal')],\n",
    "    'slope': lm_appraisal_time.params[\n",
    "        lm_appraisal_time.params.index.str.contains('quarters_since_first_appraisal')\n",
    "    ].values,\n",
    "    'ci_lower': lm_appraisal_time.conf_int().loc[\n",
    "        lm_appraisal_time.params.index.str.contains('quarters_since_first_appraisal'), 0\n",
    "    ].values,\n",
    "    'ci_upper': lm_appraisal_time.conf_int().loc[\n",
    "        lm_appraisal_time.params.index.str.contains('quarters_since_first_appraisal'), 1\n",
    "    ].values\n",
    "})\n",
    "\n",
    "# clean zone string\n",
    "df_slopes['zone'] = df_slopes['zone'].str.replace('quarters_since_first_appraisal', '')\n",
    "df_slopes['zone'] = df_slopes['zone'].str.replace('zone[T.', '')\n",
    "df_slopes['zone'] = df_slopes['zone'].str.replace(']', '')\n",
    "df_slopes['zone'] = df_slopes['zone'].str.replace(':', '')\n",
    "\n",
    "# if empty then andares-gdl\n",
    "df_slopes['zone'] = df_slopes['zone'].replace('', 'andares-gdl')\n",
    "\n",
    "# set as index\n",
    "df_slopes = df_slopes.set_index('zone')\n",
    "\n",
    "# for all zones except andares-gdl add andares-gdl value\n",
    "df_slopes['slope'] = np.where(\n",
    "    df_slopes.index == 'andares-gdl',\n",
    "    df_slopes['slope'],\n",
    "    df_slopes.loc['andares-gdl', 'slope'] + df_slopes['slope']\n",
    ")\n",
    "df_slopes['ci_lower'] = np.where(\n",
    "    df_slopes.index == 'andares-gdl',\n",
    "    df_slopes['ci_lower'],\n",
    "    df_slopes.loc['andares-gdl', 'ci_lower'] + df_slopes['ci_lower']\n",
    ")\n",
    "df_slopes['ci_upper'] = np.where(\n",
    "    df_slopes.index == 'andares-gdl',\n",
    "    df_slopes['ci_upper'],\n",
    "    df_slopes.loc['andares-gdl', 'ci_upper'] + df_slopes['ci_upper']\n",
    ")\n",
    "\n",
    "# sort by slope\n",
    "df_slopes = df_slopes.sort_values('slope')\n",
    "\n",
    "# see\n",
    "df_slopes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# plot\n",
    "sns.barplot(\n",
    "    x='slope',\n",
    "    y='zone',\n",
    "    data=df_slopes,\n",
    "    ax=ax,\n",
    "    orient='h'\n",
    ")\n",
    "\n",
    "# add confidence intervals\n",
    "for i, row in df_slopes.iterrows():\n",
    "    ax.plot(\n",
    "        [row['ci_lower'], row['ci_upper']],\n",
    "        [i, i],\n",
    "        color='black'\n",
    "    )\n",
    "\n",
    "# addorn\n",
    "plt.title(\"Velocity of Price Increase Over Time\")\n",
    "plt.xlabel(\"Price per sqm\")\n",
    "plt.ylabel(\"Zone\")\n",
    "\n",
    "# x ticks as money\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "def money_fmt(x, pos):\n",
    "    return f\"${x:,.0f}\"\n",
    "\n",
    "formatter = FuncFormatter(money_fmt)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "# show\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Importance\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "\n",
    "# calculate shap values\n",
    "cols_x = [\n",
    "    'id_clase_inmueble', \n",
    "    'property_type',\n",
    "    'elevador', 'edad_anios',\n",
    "    'regimen_propiedad', 'state_id', 'banos',\n",
    "    'medio_banos', 'estacionamiento', 'saleable_area',\n",
    "    'superficie_terreno_usable', 'distance_to_ocean', 'longitude', 'latitude',\n",
    "    'count_supermarkets_at_1km', 'count_hospitals_at_5km',\n",
    "    'count_metro_at_1km', 'count_schools_at_1km',\n",
    "    'count_restaurants_at_1km',\n",
    "    'competitors_weighted_mean_log_price_per_sqm',\n",
    "    'mean_log_valor_fisico_terreno_m2',\n",
    "    'mean_log_valor_fisico_terreno_m2_lower',\n",
    "    'mean_log_valor_fisico_terreno_m2_upper',\n",
    "    'quarters_since_first_appraisal', 'conservacion_recat',\n",
    "    'cve_vigilancia_recat'\n",
    "]\n",
    "shap_values = explainer(X_test.loc[:, cols_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "shap.summary_plot(shap_values, X_test.loc[:, cols_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "shap.plots.bar(shap_values, max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a beeswarm plot of SHAP values\n",
    "shap.plots.beeswarm(shap_values, max_display=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partal dependence plot\n",
    "shap.dependence_plot('mean_log_valor_fisico_terreno_m2', shap_values.values, X_test.loc[:, cols_x], cmap=plt.get_cmap(\"winter\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partal dependence plot\n",
    "shap.dependence_plot('quarters_since_first_appraisal', shap_values.values, X_test.loc[:, cols_x], interaction_index='id_clase_inmueble', cmap=plt.get_cmap(\"viridis\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partal dependence plot\n",
    "shap.dependence_plot('quarters_since_first_appraisal', shap_values.values, X_test.loc[:, cols_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partal dependence plot\n",
    "shap.dependence_plot('id_clase_inmueble', shap_values.values, X_test.loc[:, cols_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partal dependence plot\n",
    "shap.dependence_plot('saleable_area', shap_values.values, X_test.loc[:, cols_x], interaction_index='property_type', cmap=plt.get_cmap(\"winter\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partal dependence plot\n",
    "shap.dependence_plot('conservacion_recat', shap_values.values, X_test.loc[:, cols_x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^^maybe my categorization of remodeled is not good (move 1 position more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partal dependence plot\n",
    "shap.dependence_plot('edad_anios', shap_values.values, X_test.loc[:, cols_x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties['property_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties['cve_vigilancia_recat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate harmonic mean\n",
    "(\n",
    "    df_properties\n",
    "    .groupby('cve_vigilancia_recat')\n",
    "    .agg({'price_per_sqm': hmean})\n",
    "    .sort_values('cve_vigilancia_recat', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties['quarters_since_first_appraisal'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties.filter(like='fecha').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mds-research-stay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
